// src/lib/services/grokTwitterService.ts

import { createClient } from '@supabase/supabase-js';
import { validateEnv } from '../config/env';
import { TrendDetectionService } from './trendDetectionService';
import { NewsItem } from '@/types/news';
import fs from 'fs';
import path from 'path';

export interface Tweet {
  id: string;
  content: string;
  authorUsername: string;
  authorName?: string;
  authorFollowersCount: number;
  likesCount: number;
  retweetsCount: number;
  repliesCount: number;
  quoteCount: number;
  url?: string;
  createdAt: Date;
  isVerified: boolean;
  hashtags: string[];
}

export interface TweetHashtag {
  hashtag: string;
  tweetCount: number;
  totalLikes: number;
  totalRetweets: number;
  totalReplies: number;
  impactScore: number;
}

export class GrokTwitterService {
  private supabase;
  private trendDetectionService: TrendDetectionService;
  private twitterDataPath: string;
  
  constructor() {
    const env = validateEnv();
    this.supabase = createClient(env.supabase.url, env.supabase.serviceRoleKey);
    this.trendDetectionService = new TrendDetectionService();
    
    // Path to the Twitter data file generated by Grok
    this.twitterDataPath = path.join(process.cwd(), 'public/data/twitter-data.json');
  }
  
  /**
   * Fetch tweets based on AI-related keywords (using Grok-extracted data)
   */
  public async fetchAITweets(hours = 24): Promise<Tweet[]> {
    try {
      // Instead of calling Twitter API, read from the Grok-extracted data
      if (!fs.existsSync(this.twitterDataPath)) {
        console.error('Twitter data file not found. Run refresh-sonar-with-grok-data.js first.');
        return [];
      }
      
      const data = JSON.parse(fs.readFileSync(this.twitterDataPath, 'utf8'));
      const tweets = data.tweets || [];
      
      // Convert string dates to Date objects
      return tweets.map((tweet: any) => ({
        ...tweet,
        createdAt: new Date(tweet.createdAt)
      }));
    } catch (error) {
      console.error('Error fetching tweets from file:', error);
      return [];
    }
  }
  
  /**
   * Calculate impact score for a tweet based on engagement metrics
   */
  public calculateTweetImpactScore(tweet: Tweet): number {
    // Base formula: likes + (retweets * 2) + (quotes * 3) + replies
    // Adjusted by author's follower count (log scale to prevent domination by celebrities)
    const engagementScore = 
      tweet.likesCount + 
      (tweet.retweetsCount * 2) + 
      (tweet.quoteCount * 3) + 
      tweet.repliesCount;
    
    // Follower influence factor (log scale)
    const followerFactor = tweet.authorFollowersCount > 0 
      ? Math.log10(tweet.authorFollowersCount) / 6 // Normalize to ~0-1 range
      : 0;
    
    // Verified account bonus
    const verifiedBonus = tweet.isVerified ? 1.2 : 1;
    
    // Calculate final score
    const impactScore = engagementScore * (1 + followerFactor) * verifiedBonus;
    
    return Math.round(impactScore * 100) / 100; // Round to 2 decimal places
  }
  
  /**
   * Process tweets and store them in the database
   */
  public async storeTweets(tweets: Tweet[]): Promise<void> {
    console.log(`Processing ${tweets.length} tweets from Grok-extracted data`);
    
    for (const tweet of tweets) {
      // Calculate impact score
      const impactScore = this.calculateTweetImpactScore(tweet);
      
      // Store tweet in database
      const { data: tweetData, error: tweetError } = await this.supabase
        .from('tweets')
        .upsert({
          id: tweet.id,
          content: tweet.content,
          author_username: tweet.authorUsername,
          author_name: tweet.authorName,
          author_followers_count: tweet.authorFollowersCount,
          likes_count: tweet.likesCount,
          retweets_count: tweet.retweetsCount,
          replies_count: tweet.repliesCount,
          quote_count: tweet.quoteCount,
          url: tweet.url,
          created_at: tweet.createdAt.toISOString(),
          fetched_at: new Date().toISOString(),
          impact_score: impactScore,
          is_verified: tweet.isVerified,
          source: 'grok' // Add source to indicate this came from Grok, not direct Twitter API
        }, { onConflict: 'id' })
        .select('id')
        .single();
      
      if (tweetError) {
        console.error(`Error storing tweet ${tweet.id}:`, tweetError);
        continue;
      }
      
      // Create a simplified object that matches the expected structure for detectTechnologies
      const tweetAsArticle: NewsItem = {
        id: tweet.id,
        title: tweet.content,
        summary: '',
        url: tweet.url || '',
        source_id: 'twitter-via-grok', // Indicate this came from Grok
        published_date: tweet.createdAt,
        language: 'en',
        importance_score: impactScore
      };
      
      // Detect technologies mentioned in the tweet
      const technologies = this.trendDetectionService.detectTechnologies(tweetAsArticle);
      
      // Link tweet to technologies
      for (const [technology, score] of technologies.entries()) {
        // Check if technology exists in database
        const { data: techData, error: techError } = await this.supabase
          .from('ai_technologies')
          .select('id')
          .eq('name', technology)
          .single();
        
        if (techError || !techData) {
          continue; // Skip if technology not found
        }
        
        // Link tweet to technology
        const { error: linkError } = await this.supabase
          .from('tweet_technologies')
          .upsert({
            tweet_id: tweet.id,
            technology_id: techData.id,
            relevance_score: score
          }, { onConflict: 'tweet_id,technology_id' });
        
        if (linkError) {
          console.error(`Error linking tweet ${tweet.id} to technology ${technology}:`, linkError);
        }
        
        // Update trend data
        const today = new Date();
        const dateString = today.toISOString().split('T')[0];
        
        // Check if we have a trend point for today
        const { data: trendPoint, error: trendError } = await this.supabase
          .from('technology_trend_points')
          .select('id, tweet_mention_count, social_impact_score')
          .eq('technology_id', techData.id)
          .gte('date', `${dateString}T00:00:00Z`)
          .lt('date', `${dateString}T23:59:59Z`)
          .single();
        
        if (trendError || !trendPoint) {
          // Create new trend point or skip if error
          continue;
        } else {
          // Update existing trend point with tweet data
          const { error: updateTrendError } = await this.supabase
            .from('technology_trend_points')
            .update({
              tweet_mention_count: trendPoint.tweet_mention_count + 1,
              social_impact_score: (trendPoint.social_impact_score + impactScore) / 2
            })
            .eq('id', trendPoint.id);
          
          if (updateTrendError) {
            console.error(`Error updating trend point for ${technology}:`, updateTrendError);
          }
        }
      }
      
      // Process hashtags
      for (const hashtag of tweet.hashtags) {
        // Skip very short hashtags
        if (hashtag.length < 3) continue;
        
        // Check if hashtag exists
        const { data: hashtagData, error: hashtagError } = await this.supabase
          .from('tweet_hashtags')
          .select('id, tweet_count, total_likes, total_retweets, total_replies, impact_score')
          .eq('hashtag', hashtag)
          .single();
        
        if (hashtagError) {
          // Create new hashtag
          const { data: newHashtag, error: createError } = await this.supabase
            .from('tweet_hashtags')
            .insert({
              hashtag,
              tweet_count: 1,
              total_likes: tweet.likesCount,
              total_retweets: tweet.retweetsCount,
              total_replies: tweet.repliesCount,
              impact_score: impactScore,
              first_seen: tweet.createdAt.toISOString(),
              last_seen: tweet.createdAt.toISOString(),
              source: 'grok' // Add source to indicate this came from Grok
            })
            .select('id')
            .single();
          
          if (createError || !newHashtag) {
            console.error(`Error creating hashtag ${hashtag}:`, createError);
            continue;
          }
          
          // Link tweet to hashtag
          const { error: linkError } = await this.supabase
            .from('tweet_hashtag_links')
            .insert({
              tweet_id: tweet.id,
              hashtag_id: newHashtag.id
            });
          
          if (linkError) {
            console.error(`Error linking tweet ${tweet.id} to hashtag ${hashtag}:`, linkError);
          }
        } else {
          // Update existing hashtag
          const { error: updateError } = await this.supabase
            .from('tweet_hashtags')
            .update({
              tweet_count: hashtagData.tweet_count + 1,
              total_likes: hashtagData.total_likes + tweet.likesCount,
              total_retweets: hashtagData.total_retweets + tweet.retweetsCount,
              total_replies: hashtagData.total_replies + tweet.repliesCount,
              impact_score: (hashtagData.impact_score + impactScore) / 2,
              last_seen: tweet.createdAt.toISOString(),
              source: 'grok' // Update source to indicate this came from Grok
            })
            .eq('id', hashtagData.id);
          
          if (updateError) {
            console.error(`Error updating hashtag ${hashtag}:`, updateError);
            continue;
          }
          
          // Link tweet to hashtag
          const { error: linkError } = await this.supabase
            .from('tweet_hashtag_links')
            .insert({
              tweet_id: tweet.id,
              hashtag_id: hashtagData.id
            });
          
          if (linkError) {
            console.error(`Error linking tweet ${tweet.id} to hashtag ${hashtag}:`, linkError);
          }
        }
      }
    }
  }
  
  /**
   * Get top hashtags by impact score
   */
  public async getTopHashtags(limit = 10): Promise<TweetHashtag[]> {
    try {
      // First try to get from database
      const { data, error } = await this.supabase
        .from('tweet_hashtags')
        .select('*')
        .order('impact_score', { ascending: false })
        .limit(limit);
      
      if (!error && data && data.length > 0) {
        return data.map(item => ({
          hashtag: item.hashtag,
          tweetCount: item.tweet_count,
          totalLikes: item.total_likes,
          totalRetweets: item.total_retweets,
          totalReplies: item.total_replies,
          impactScore: item.impact_score
        }));
      }
      
      // If database fetch fails or returns no data, use the file
      if (!fs.existsSync(this.twitterDataPath)) {
        console.error('Twitter data file not found. Run refresh-sonar-with-grok-data.js first.');
        return [];
      }
      
      const fileData = JSON.parse(fs.readFileSync(this.twitterDataPath, 'utf8'));
      const hashtags = fileData.hashtags || [];
      
      return hashtags.slice(0, limit);
    } catch (error) {
      console.error('Error fetching top hashtags:', error);
      return [];
    }
  }
  
  /**
   * Get top tweets by impact score
   */
  public async getTopTweets(limit = 10): Promise<Tweet[]> {
    try {
      // First try to get from database
      const { data, error } = await this.supabase
        .from('tweets')
        .select('*')
        .order('impact_score', { ascending: false })
        .limit(limit);
      
      if (!error && data && data.length > 0) {
        return data.map(item => ({
          id: item.id,
          content: item.content,
          authorUsername: item.author_username,
          authorName: item.author_name,
          authorFollowersCount: item.author_followers_count,
          likesCount: item.likes_count,
          retweetsCount: item.retweets_count,
          repliesCount: item.replies_count,
          quoteCount: item.quote_count,
          url: item.url,
          createdAt: new Date(item.created_at),
          isVerified: item.is_verified,
          hashtags: [] // We don't load hashtags here for simplicity
        }));
      }
      
      // If database fetch fails or returns no data, use the file
      if (!fs.existsSync(this.twitterDataPath)) {
        console.error('Twitter data file not found. Run refresh-sonar-with-grok-data.js first.');
        return [];
      }
      
      const fileData = JSON.parse(fs.readFileSync(this.twitterDataPath, 'utf8'));
      const tweets = fileData.tweets || [];
      
      // Convert string dates to Date objects and sort by impact score
      const processedTweets = tweets
        .map((tweet: any) => ({
          ...tweet,
          createdAt: new Date(tweet.createdAt)
        }))
        .sort((a: Tweet, b: Tweet) => {
          const scoreA = this.calculateTweetImpactScore(a);
          const scoreB = this.calculateTweetImpactScore(b);
          return scoreB - scoreA;
        });
      
      return processedTweets.slice(0, limit);
    } catch (error) {
      console.error('Error fetching top tweets:', error);
      return [];
    }
  }
  
  /**
   * Get tweets related to a specific technology
   */
  public async getTweetsByTechnology(technologyId: number, limit = 10): Promise<Tweet[]> {
    try {
      // First try to get from database
      const { data, error } = await this.supabase
        .from('tweet_technologies')
        .select(`
          relevance_score,
          tweets(*)
        `)
        .eq('technology_id', technologyId)
        .order('relevance_score', { ascending: false })
        .limit(limit);
      
      if (!error && data && data.length > 0) {
        const tweets: Tweet[] = [];
        
        for (const item of data) {
          if (item.tweets) {
            const tweetData = item.tweets as any; // Cast to any to avoid TypeScript errors
            tweets.push({
              id: tweetData.id,
              content: tweetData.content,
              authorUsername: tweetData.author_username,
              authorName: tweetData.author_name,
              authorFollowersCount: tweetData.author_followers_count,
              likesCount: tweetData.likes_count,
              retweetsCount: tweetData.retweets_count,
              repliesCount: tweetData.replies_count,
              quoteCount: tweetData.quote_count,
              url: tweetData.url,
              createdAt: new Date(tweetData.created_at),
              isVerified: tweetData.is_verified,
              hashtags: [] // We don't load hashtags here for simplicity
            });
          }
        }
        
        return tweets;
      }
      
      // If database fetch fails or returns no data, use all tweets from file
      // and filter by technology keywords
      if (!fs.existsSync(this.twitterDataPath)) {
        console.error('Twitter data file not found. Run refresh-sonar-with-grok-data.js first.');
        return [];
      }
      
      const fileData = JSON.parse(fs.readFileSync(this.twitterDataPath, 'utf8'));
      const allTweets = fileData.tweets || [];
      
      // Get technology keywords
      const { data: techData, error: techError } = await this.supabase
        .from('ai_technologies')
        .select('name')
        .eq('id', technologyId)
        .single();
      
      if (techError || !techData) {
        console.error(`Error fetching technology ${technologyId}:`, techError);
        return [];
      }
      
      // Get keywords for this technology
      const technologyName = techData.name;
      const technologyKeywords = this.trendDetectionService.getTechnologyKeywords();
      const keywords = (technologyKeywords as any)[technologyName.toLowerCase()] || [];
      
      // Filter tweets that mention any of the keywords
      const relatedTweets = allTweets
        .filter((tweet: any) => {
          const content = tweet.content.toLowerCase();
          return keywords.some((keyword: string) => content.includes(keyword.toLowerCase())) ||
                 content.includes(technologyName.toLowerCase());
        })
        .map((tweet: any) => ({
          ...tweet,
          createdAt: new Date(tweet.createdAt)
        }));
      
      // Sort by relevance (number of matching keywords)
      relatedTweets.sort((a: any, b: any) => {
        const contentA = a.content.toLowerCase();
        const contentB = b.content.toLowerCase();
        
        const matchesA = keywords.filter((keyword: string) => contentA.includes(keyword.toLowerCase())).length;
        const matchesB = keywords.filter((keyword: string) => contentB.includes(keyword.toLowerCase())).length;
        
        return matchesB - matchesA;
      });
      
      return relatedTweets.slice(0, limit);
    } catch (error) {
      console.error(`Error fetching tweets for technology ${technologyId}:`, error);
      return [];
    }
  }
}